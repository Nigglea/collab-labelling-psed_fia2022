{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cf393ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torchaudio\n",
    "import torch\n",
    "import yaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b152f154",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_desc_file(_desc_file,__class_labels):\n",
    "    _desc_dict = dict()\n",
    "    for i,line in enumerate(open(_desc_file)):\n",
    "        if i >0:\n",
    "            words = line.strip().split(',')\n",
    "            name = words[0]\n",
    "            if name not in _desc_dict:\n",
    "                _desc_dict[name] = list()\n",
    "            _desc_dict[name].append([float(words[-3]), float(words[-2]), __class_labels[words[-1]]])\n",
    "    return _desc_dict\n",
    "\n",
    "def transformation(signal,SAMPLE_RATE,N_FFT,HOP,N_MELS,trans=\"logmel\"):\n",
    "    if trans == \"mel\":\n",
    "        transf = torchaudio.transforms.MelSpectrogram(\n",
    "        sample_rate=SAMPLE_RATE,\n",
    "        n_fft=N_FFT,\n",
    "        hop_length=HOP ,\n",
    "        n_mels=N_MELS\n",
    "        )\n",
    "        signal = transf(signal)\n",
    "    if trans == \"logmel\":\n",
    "        transf = torchaudio.transforms.MelSpectrogram(\n",
    "        sample_rate=SAMPLE_RATE,\n",
    "        n_fft=N_FFT,\n",
    "        hop_length=HOP ,\n",
    "        n_mels=N_MELS,\n",
    "        normalized = True\n",
    "        )\n",
    "        signal = transf(signal)\n",
    "        signal = torch.log(signal+1e-5)\n",
    "    return signal\n",
    "\n",
    "def get_audio_sample_label(signal,target_sample_rate,hop, audio_sample_path,annotations_file,labels):\n",
    "    label = np.zeros((len(labels), signal.shape[1]))\n",
    "    filenames = load_desc_file(annotations_file,labels)\n",
    "    tmp_data = np.array(filenames[audio_sample_path])\n",
    "    frame_start = np.floor(tmp_data[:, 0] * target_sample_rate / hop).astype(int)\n",
    "    frame_end = np.ceil(tmp_data[:, 1] * target_sample_rate / hop).astype(int)\n",
    "    se_class = tmp_data[:, 2].astype(int)\n",
    "    for ind, val in enumerate(se_class):\n",
    "        label[val, frame_start[ind]:frame_end[ind]] = 1\n",
    "    return label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39ff3da6",
   "metadata": {},
   "outputs": [],
   "source": [
    "taxonomy_path = 'taxonomy.yml'\n",
    "labels_path = 'metadata_jak_en.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed4af6c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_labels = pd.read_csv(labels_path)\n",
    "df_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90d80536",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(taxonomy_path) as taxpath:\n",
    "    taxonomy = yaml.safe_load(taxpath)\n",
    "    taxo = taxonomy['taxonomy']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec2fe682",
   "metadata": {},
   "outputs": [],
   "source": [
    "SAMPLE_RATE = 44100\n",
    "LEN_SEC = 300\n",
    "LEN_SAMPLES = LEN_SEC*SAMPLE_RATE\n",
    "N_FFT = 2048\n",
    "HOP = int(N_FFT/2)\n",
    "N_MELS = 40"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b14bb98",
   "metadata": {},
   "outputs": [],
   "source": [
    "signal_toy = 50*torch.ones(LEN_SAMPLES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96d5835b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "audio_samples_path = df_labels.Filename.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd635967",
   "metadata": {},
   "outputs": [],
   "source": [
    "sigmel = transformation(signal_toy,SAMPLE_RATE,N_FFT,HOP,N_MELS,trans=\"logmel\")\n",
    "sigmel.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97098ec1",
   "metadata": {},
   "outputs": [],
   "source": [
    "annotations_frames = {}\n",
    "for a in audio_samples_path:\n",
    "    n,t = a.split('.')\n",
    "    an_a = get_audio_sample_label(sigmel,SAMPLE_RATE,HOP, a,labels_path,taxo)\n",
    "    annotations_frames[n]=an_a"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fia",
   "language": "python",
   "name": "fia"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
